% Encoding: UTF-8

@Article{velten2013femto,
  author    = {Velten, Andreas and Wu, Di and Jarabo, Adrian and Masia, Belen and Barsi, Christopher and Joshi, Chinmaya and Lawson, Everett and Bawendi, Moungi and Gutierrez, Diego and Raskar, Ramesh},
  journal   = {ACM Trans. Graphics},
  title     = {Femto-photography: capturing and visualizing the propagation of light},
  year      = {2013},
  number    = {4},
  pages     = {1--8},
  volume    = {32},
  publisher = {ACM New York, NY, USA},
}

@Article{laurenzis2014nonline,
  author    = {Laurenzis, Martin and Velten, Andreas},
  journal   = {Opt. Eng},
  title     = {Non-Line-of-Sight laser gated viewing of scattered photons},
  year      = {2014},
  number    = {2},
  pages     = {023102},
  volume    = {53},
  publisher = {International Society for Optics and Photonics},
}

@InProceedings{o2017reconstructing,
  author    = {O'Toole, Matthew and Heide, Felix and Lindell, David B and Zang, Kai and Diamond, Steven and Wetzstein, Gordon},
  booktitle = {Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
  title     = {Reconstructing transient images from single-photon sensors},
  year      = {2017},
  pages     = {1539--1547},
}
@techreport{ramesh20085d,
  title={{5D time-light transport matrix: What can we reason about scene properties?}},
  author={Ramesh, Raskar and Davis, James},
  year={2008}
}

@Article{Velten2012,
  author          = {Velten, Andreas and Willwacher, Thomas and Gupta, Otkrist and Veeraraghavan, Ashok and Bawendi, Moungi G. and Raskar, Ramesh},
  journal         = {Nat. Commun.},
  title           = {{Recovering three-dimensional shape around a corner using ultrafast time-of-flight imaging}},
  year            = {2012},
  issn            = {20411723},
  volume          = {3},
  abstract        = {The recovery of objects obscured by scattering is an important goal in imaging and has been approached by exploiting, for example, coherence properties, ballistic photons or penetrating wavelengths. Common methods use scattered light transmitted through an occluding material, although these fail if the occluder is opaque. Light is scattered not only by transmission through objects, but also by multiple reflection from diffuse surfaces in a scene. This reflected light contains information about the scene that becomes mixed by the diffuse reflections before reaching the image sensor. This mixing is difficult to decode using traditional cameras. Here we report the combination of a time-of-flight technique and computational reconstruction algorithms to untangle image information mixed by diffuse reflection. We demonstrate a three-dimensional range camera able to look around a corner using diffusely reflected light that achieves sub-millimetre depth precision and centimetre lateral precision over 40 cm×40 cm×40 cm of hidden space. {\textcopyright} 2012 Macmillan Publishers Limited. All rights reserved.},
  doi             = {10.1038/ncomms1747},
  file            = {:D$\backslash$:/Download/ncomms1747.pdf:pdf},
  mendeley-groups = {NLOS,NLOS/iterative},
  publisher       = {Nature Publishing Group},
}

@Article{LaManna2019,
  author          = {{La Manna}, Marco and Kine, Fiona and Breitbach, Eric and Jackson, Jonathan and Sultan, Talha and Velten, Andreas},
  journal         = {IEEE Trans. Pattern Anal. Mach. Intell.},
  title           = {{Error Backprojection Algorithms for Non-Line-of-Sight Imaging}},
  year            = {2019},
  issn            = {19393539},
  number          = {7},
  pages           = {1615--1626},
  volume          = {41},
  abstract        = {Recent advances in computer vision and inverse light transport theory have resulted in several non-line-of-sight imaging techniques. These techniques use photon time-of-flight information encoded in light after multiple, diffuse reflections to reconstruct a three-dimensional scene. In this paper, we propose and describe two iterative backprojection algorithms, the additive error backprojection (AEB) and multiplicative error backprojection (MEB), whose goal is to improve the reconstruction of the scene under investigation over non-iterative backprojection algorithms. We evaluate the proposed algorithms' performance applied to simulated and real data (gathered from an experimental setup where the system needs to reconstruct an unknown scene). Results show that the proposed iterative algorithms are able to provide better reconstruction than the unfiltered, non-iterative backprojection algorithm for both simulated and physical scenes, but are more sensitive to errors in the light transport model.},
  doi             = {10.1109/TPAMI.2018.2843363},
  file            = {:D$\backslash$:/Download/08371271.pdf:pdf},
  keywords        = {Non-Line-of-Sight (NLOS) imaging,algebraic reconstruction technique (ART),kaczmarz method,seeing-around-corners,time-of-flight},
  mendeley-groups = {NLOS,NLOS/iterative},
  pmid            = {29993536},
  publisher       = {IEEE},
}

@Article{Arellano2017,
  author    = {Arellano, Victor and Gutierrez, Diego and Jarabo, Adrian},
  journal   = {Opt. Express},
  title     = {Fast back-projection for non-line of sight reconstruction},
  year      = {2017},
  number    = {10},
  pages     = {11574--11583},
  volume    = {25},
  publisher = {Optical Society of America},
}

@Article{Laurenzis2014,
  author          = {Laurenzis, Martin and Velten, Andreas},
  journal         = {J. Electron. Imaging},
  title           = {{Feature selection and back-projection algorithms for nonline-of-sight laser–gated viewing}},
  year            = {2014},
  issn            = {1017-9909},
  number          = {6},
  pages           = {063003},
  volume          = {23},
  abstract        = {We discuss new approaches to analyze laser-gated viewing data for nonline-of-sight vision with a frame-to-frame back-projection as well as feature selection algorithms. Although first back-projection approaches use time transients for each pixel, our method has the ability to calculate the projection of imaging data on the voxel space for each frame. Further, different data analysis algorithms and their sequential application were studied with the aim of identifying and selecting signals from different target positions. A slight modification of commonly used filters leads to a powerful selection of local maximum values. It is demonstrated that the choice of the filter has an impact on the selectivity i.e., multiple target detection as well as on the localization precision.},
  doi             = {10.1117/1.jei.23.6.063003},
  file            = {:D$\backslash$:/Download/063003{\_}1.pdf:pdf},
  keywords        = {11,2014,7,accepted for publication oct,feature selection algorithm,laser-gated viewing,nonline-of-sight vision,paper 14383 received jul,published online,revised manuscript received sep,see around the corner},
  mendeley-groups = {NLOS,NLOS/iterative},
}

@Article{Ahn2019,
  author          = {Ahn, Byeongjoo and Dave, Akshat and Veeraraghavan, Ashok and Gkioulekas, Ioannis and Sankaranarayanan, Aswin},
  journal         = {Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
  title           = {{Convolutional approximations to the general non-line-of-sight imaging operator}},
  year            = {2019},
  issn            = {15505499},
  pages           = {7888--7898},
  volume          = {2019-October},
  abstract        = {Non-line-of-sight (NLOS) imaging aims to reconstruct scenes outside the field of view of an imaging system. A common approach is to measure the so-called light transients, which facilitates reconstructions through ellipsoidal tomography that involves solving a linear least-squares. Unfortunately, the corresponding linear operator is very high-dimensional and lacks structures that facilitate fast solvers, and so, the ensuing optimization is a computationally daunting task. We introduce a computationally tractable framework for solving the ellipsoidal tomography problem. Our main observation is that the Gram of the ellipsoidal tomography operator is convolutional, either exactly under certain idealized imaging conditions, or approximately in practice. This, in turn, allows us to obtain the ellipsoidal tomography solution by using efficient deconvolution procedures to solve a linear least-squares problem involving the Gram operator. The computational tractability of our approach also facilitates the use of various regularizers during the deconvolution procedure. We demonstrate the advantages of our framework in a variety of simulated and real experiments.},
  doi             = {10.1109/ICCV.2019.00798},
  file            = {:D$\backslash$:/Download/Ahn{\_}Convolutional{\_}Approximations{\_}to{\_}the{\_}General{\_}Non-Line-of-Sight{\_}Imaging{\_}Operator{\_}ICCV{\_}2019{\_}paper.pdf:pdf},
  isbn            = {9781728148038},
  mendeley-groups = {NLOS/iterative},
}

@Article{Tsai2019,
  author          = {Tsai, Chia Yin and Sankaranarayanan, Aswin C. and Gkioulekas, Ioannis},
  journal         = {Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
  title           = {{Beyond volumetric albedo - A surface optimization framework for non-line-of-sight imaging}},
  year            = {2019},
  issn            = {10636919},
  pages           = {1545--1555},
  volume          = {2019-June},
  abstract        = {Non-Line-of-Sight (NLOS) imaging is the problem of reconstructing properties of scenes occluded from a sensor, using measurements of light that indirectly travels from the occluded scene to the sensor through intermediate diffuse reflections. We introduce an analysis-by-synthesis framework that can reconstruct complex shape and reflectance of an NLOS object. Our framework deviates from prior work on NLOS reconstruction, by directly optimizing for a surface representation of the NLOS object, in place of commonly employed volumetric representations. At the core of our framework is a new rendering formulation that efficiently computes derivatives of radiometric measurements with respect to NLOS geometry and reflectance, while accurately modeling the underlying light transport physics. By coupling this with stochastic optimization and geometry processing techniques, we are able to reconstruct NLOS surface at a level of detail significantly exceeding what is possible with previous volumetric reconstruction methods.},
  doi             = {10.1109/CVPR.2019.00164},
  file            = {:D$\backslash$:/Download/Tsai{\_}Beyond{\_}Volumetric{\_}Albedo{\_}--{\_}A{\_}Surface{\_}Optimization{\_}Framework{\_}for{\_}Non-Line-Of-Sight{\_}CVPR{\_}2019{\_}paper.pdf:pdf},
  isbn            = {9781728132938},
  keywords        = {Computational Photography,Physics-based Vision and Shape-from-X},
  mendeley-groups = {NLOS,NLOS/iterative},
}
@article{Iseringhausen2018,
abstract = {Being able to see beyond the direct line of sight is an intriguing prospective and could benefit a wide variety of important applications. Recent work has demonstrated that time-resolved measurements of indirect diffuse light contain valuable information for reconstructing shape and reflectance properties of objects located around a corner. In this paper, we introduce a novel reconstruction scheme that, by design, produces solutions that are consistent with state-of-the-art physically-based rendering. Our method combines an efficient forward model (a custom renderer for time-resolved three-bounce indirect light transport) with an optimization framework to reconstruct object geometry in an analysis-by-synthesis sense. We evaluate our algorithm on a variety of synthetic and experimental input data, and show that it gracefully handles uncooperative scenes with high levels of noise or non-diffuse material reflectance.},
archivePrefix = {arXiv},
arxivId = {1809.08044},
author = {Iseringhausen, Julian and Hullin, Matthias B.},
eprint = {1809.08044},
file = {:D$\backslash$:/Download/document (1).pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {Analysis by synthesis,Inverse light transport,Plenoptic imaging},
mendeley-groups = {NLOS,NLOS/iterative},
number = {1},
pages = {1--14},
title = {{Non-line-of-sight reconstruction using efficient transient rendering}},
volume = {39},
year = {2018}
}

@Article{Tsai2017,
  author          = {Tsai, Chia Yin and Kutulakos, Kiriakos N. and Narasimhan, Srinivasa G. and Sankaranarayanan, Aswin C.},
  journal         = {Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
  title           = {{The geometry of first-returning photons for non-line-of-sight imaging}},
  year            = {2017},
  pages           = {2336--2344},
  volume          = {2017-January},
  abstract        = {Non-line-of-sight (NLOS) imaging utilizes the full 5D light transient measurements to reconstruct scenes beyond the camera's field of view. Mathematically, this requires solving an elliptical tomography problem that unmixes the shape and albedo from spatially-multiplexed measurements of the NLOS scene. In this paper, we propose a new approach for NLOS imaging by studying the properties of first-returning photons from three-bounce light paths. We show that the times of flight of first-returning photons are dependent only on the geometry of the NLOS scene and each observation is almost always generated from a single NLOS scene point. Exploiting these properties, we derive a space carving algorithm for NLOS scenes. In addition, by assuming local planarity, we derive an algorithm to localize NLOS scene points in 3D and estimate their surface normals. Our methods do not require either the full transient measurements or solving the hard elliptical tomography problem. We demonstrate the effectiveness of our methods through simulations as well as real data captured from a SPAD sensor.},
  doi             = {10.1109/CVPR.2017.251},
  file            = {:D$\backslash$:/Download/Tsai{\_}The{\_}Geometry{\_}of{\_}CVPR{\_}2017{\_}paper.pdf:pdf},
  isbn            = {9781538604571},
  mendeley-groups = {NLOS/geometry},
}

@Article{Xin2019,
  author          = {Xin, Shumian and Nousias, Sotiris and Kutulakos, Kiriakos N. and Sankaranarayanan, Aswin C. and Narasimhan, Srinivasa G. and Gkioulekas, Ioannis},
  journal         = {Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
  title           = {{A theory of fermat paths for non-line-of-sight shape reconstruction}},
  year            = {2019},
  issn            = {10636919},
  pages           = {6793--6802},
  volume          = {2019-June},
  abstract        = {We present a novel theory of Fermat paths of light between a known visible scene and an unknown object not in the line of sight of a transient camera. These light paths either obey specular reflection or are reflected by the object's boundary, and hence encode the shape of the hidden object. We prove that Fermat paths correspond to discontinuities in the transient measurements. We then derive a novel constraint that relates the spatial derivatives of the path lengths at these discontinuities to the surface normal. Based on this theory, we present an algorithm, called Fermat Flow, to estimate the shape of the non-line-of-sight object. Our method allows, for the first time, accurate shape recovery of complex objects, ranging from diffuse to specular, that are hidden around the corner as well as hidden behind a diffuser. Finally, our approach is agnostic to the particular technology used for transient imaging. As such, we demonstrate mm-scale shape recovery from pico-second scale transients using a SPAD and ultrafast laser, as well as micron-scale reconstruction from femto-second scale transients using interferometry. We believe our work is a significant advance over the state-of-the-art in non-line-of-sight imaging.},
  doi             = {10.1109/CVPR.2019.00696},
  file            = {:D$\backslash$:/Download/Xin{\_}A{\_}Theory{\_}of{\_}Fermat{\_}Paths{\_}for{\_}Non-Line-Of-Sight{\_}Shape{\_}Reconstruction{\_}CVPR{\_}2019{\_}paper.pdf:pdf},
  isbn            = {9781728132938},
  keywords        = {Computational Photography,Physics-based Vision and Shape-from-X},
  mendeley-groups = {NLOS/geometry},
}

@Article{DavidB.Lindell2019,
  author          = {{David B. Lindell} and {Gordon Wetzstein} and {Matthew O'Toole}},
  journal         = {ACM Trans. Graphics},
  title           = {{Wave-Based Non-Line-of-Sight Imaging using Fast f-k Migration}},
  year            = {2019},
  number          = {4},
  pages           = {116},
  volume          = {38},
  file            = {:D$\backslash$:/Download/3306346.3322937.pdf:pdf},
  mendeley-groups = {NLOS,NLOS/diffraction based},
  url             = {http://www.computationalimaging.org/publications/nlos-fk/},
}
@article{Otoole2018,
abstract = {How to image objects that are hidden from a camera's view is a problem of fundamental importance to many fields of research, with applications in robotic vision, defence, remote sensing, medical imaging and autonomous vehicles. Non-line-of-sight (NLOS) imaging at macroscopic scales has been demonstrated by scanning a visible surface with a pulsed laser and a time-resolved detector. Whereas light detection and ranging (LIDAR) systems use such measurements to recover the shape of visible objects from direct reflections, NLOS imaging reconstructs the shape and albedo of hidden objects from multiply scattered light. Despite recent advances, NLOS imaging has remained impractical owing to the prohibitive memory and processing requirements of existing reconstruction algorithms, and the extremely weak signal of multiply scattered light. Here we show that a confocal scanning procedure can address these challenges by facilitating the derivation of the light-cone transform to solve the NLOS reconstruction problem. This method requires much smaller computational and memory resources than previous reconstruction methods do and images hidden objects at unprecedented resolution. Confocal scanning also provides a sizeable increase in signal and range when imaging retroreflective objects. We quantify the resolution bounds of NLOS imaging, demonstrate its potential for real-time tracking and derive efficient algorithms that incorporate image priors and a physically accurate noise model. Additionally, we describe successful outdoor experiments of NLOS imaging under indirect sunlight.},
author = {Otoole, Matthew and Lindell, David B. and Wetzstein, Gordon},
doi = {10.1038/nature25489},
file = {:D$\backslash$:/Download/nature25489.pdf:pdf},
issn = {14764687},
journal = {Nat.},
mendeley-groups = {NLOS/diffraction based},
number = {7696},
pages = {338--341},
pmid = {29513650},
publisher = {Nature Publishing Group},
title = {{Confocal non-line-of-sight imaging based on the light-cone transform}},
volume = {555},
year = {2018}
}
@article{Liu2019,
abstract = {Non-line-of-sight imaging allows objects to be observed when partially or fully occluded from direct view, by analysing indirect diffuse reflections off a secondary relay surface. Despite many potential applications1–9, existing methods lack practical usability because of limitations including the assumption of single scattering only, ideal diffuse reflectance and lack of occlusions within the hidden scene. By contrast, line-of-sight imaging systems do not impose any assumptions about the imaged scene, despite relying on the mathematically simple processes of linear diffractive wave propagation. Here we show that the problem of non-line-of-sight imaging can also be formulated as one of diffractive wave propagation, by introducing a virtual wave field that we term the phasor field. Non-line-of-sight scenes can be imaged from raw time-of-flight data by applying the mathematical operators that model wave propagation in a conventional line-of-sight imaging system. Our method yields a new class of imaging algorithms that mimic the capabilities of line-of-sight cameras. To demonstrate our technique, we derive three imaging algorithms, modelled after three different line-of-sight systems. These algorithms rely on solving a wave diffraction integral, namely the Rayleigh–Sommerfeld diffraction integral. Fast solutions to Rayleigh–Sommerfeld diffraction and its approximations are readily available, benefiting our method. We demonstrate non-line-of-sight imaging of complex scenes with strong multiple scattering and ambient light, arbitrary materials, large depth range and occlusions. Our method handles these challenging cases without explicitly inverting a light-transport model. We believe that our approach will help to unlock the potential of non-line-of-sight imaging and promote the development of relevant applications not restricted to laboratory conditions.},
author = {Liu, Xiaochun and Guill{\'{e}}n, Ib{\'{o}}n and {La Manna}, Marco and Nam, Ji Hyun and Reza, Syed Azer and {Huu Le}, Toan and Jarabo, Adrian and Gutierrez, Diego and Velten, Andreas},
doi = {10.1038/s41586-019-1461-3},
file = {:D$\backslash$:/Download/s41586-019-1461-3.pdf:pdf},
issn = {14764687},
journal = {Nat.},
mendeley-groups = {NLOS/diffraction based,NLOS/plane-based,NLOS/PhaseField},
number = {7771},
pages = {620--623},
pmid = {31384042},
publisher = {Springer US},
title = {{Non-line-of-sight imaging using phasor-field virtual wave optics}},
url = {http://dx.doi.org/10.1038/s41586-019-1461-3},
volume = {572},
year = {2019}
}

@Article{Pediredla2017,
  author          = {Pediredla, Adithya Kumar and Buttafava, Mauro and Tosi, Alberto and Cossairt, Oliver and Veeraraghavan, Ashok},
  journal         = {Proc. IEEE Int. Conf. Comput. Photography (ICCP)},
  title           = {{Reconstructing rooms using photon echoes: A plane based model and reconstruction algorithm for looking around the corner}},
  year            = {2017},
  abstract        = {Can we reconstruct the entire internal shape of a room if all we can directly observe is a small portion of one internal wall, presumably through a window in the room? While conventional wisdom may indicate that this is not possible, motivated by recent work on 'looking around corners', we show that one can exploit light echoes to reconstruct the internal shape of hidden rooms. Existing techniques for looking around the corner using transient images model the hidden volume using voxels and try to explain the captured transient response as the sum of the transient responses obtained from individual voxels. Such a technique inherently suffers from challenges with regards to low signal to background ratios (SBR) and has difficulty scaling to larger volumes. In contrast, in this paper, we argue for using a plane-based model for the hidden surfaces. We demonstrate that such a plane-based model results in much higher SBR while simultaneously being amenable to larger spatial scales. We build an experimental prototype composed of a pulsed laser source and a single-photon avalanche detector (SPAD) that can achieve a time resolution of about 30ps and demonstrate high-fidelity reconstructions both of individual planes in a hidden volume and for reconstructing entire polygonal rooms composed of multiple planar walls.},
  doi             = {10.1109/ICCPHOT.2017.7951478},
  file            = {:D$\backslash$:/Download/07951478.pdf:pdf},
  isbn            = {9781509057450},
  mendeley-groups = {NLOS/plane-based},
  publisher       = {IEEE},
}

@Article{Teichman2019,
  author          = {Teichman, Jeremy A.},
  journal         = {Opt. Express},
  title           = {{Phasor field waves: a mathematical treatment}},
  year            = {2019},
  issn            = {1094-4087},
  number          = {20},
  pages           = {27500},
  volume          = {27},
  abstract        = {Non-line-of-sight imaging can use modulated sources to preserve phase information at the modulation wavelength through a scattering interaction with a diffuser or an optically rough wall that scrambles the optical phase. Reza, et al. formulated the preserved information as a phasor field propagation [Opt. Express (in review)] for time-of-flight imaging of hidden scenes using diffusely scattered light. This paper presents a derivation of the underpinning of phasor field propagation to establish its rigor. The result is an expression for the time-modulated irradiance (phasor field) produced by time-modulated coherent illumination of a phase-scrambling aperture. Speckle effects, representing variance in the phasor field, are also quantified.},
  doi             = {10.1364/oe.27.027500},
  file            = {:D$\backslash$:/Download/oe-27-20-27500.pdf:pdf},
  mendeley-groups = {NLOS/PhaseField},
  pmid            = {31684515},
}
@article{Dove2019,
abstract = {The phasor field has been shown to be a valuable tool for non-line-of-sight imaging. We present a formal analysis of phasor-field imaging using paraxial wave optics. Then, we derive a set of propagation primitives|using the two-frequency, spatial Wigner distribution|that extend the purview of phasor-field imaging. We use these primitives to analyze a set of simple imaging scenarios involving occluded and unoccluded geometries with modulated and unmodulated light. These scenarios demonstrate how to apply the primitives in practice and reveal what kind of insights can be expected from them.},
archivePrefix = {arXiv},
arxivId = {1903.02365},
author = {Dove, Justin and Shapiro, Jeffrey H.},
doi = {10.1364/oe.27.018016},
eprint = {1903.02365},
file = {:D$\backslash$:/Download/oe-27-13-18016.pdf:pdf},
issn = {23318422},
journal = {arXiv},
mendeley-groups = {NLOS/PhaseField},
number = {13},
pmid = {31252751},
title = {{Paraxial theory of phasor-field imaging}},
volume = {27},
year = {2019}
}

@Article{Liu2020,
  author          = {Liu, Xiaochun and Velten, Andreas},
  journal         = {Proc. IEEE Int. Conf. Comput. Photography (ICCP)},
  title           = {{The role of wigner distribution function in non-line-of-sight imaging}},
  year            = {2020},
  abstract        = {Non-Line-of-Sight imaging has been linked to wave diffraction by the recent phasor field method. In wave optics, the Wigner Distribution Function description for an optical imaging system is a powerful analytical tool for modeling the imaging process with geometrical transformations. In this paper, we focus on illustrating the relation between captured signals and hidden objects in the Wigner Distribution domain. The Wigner Distribution Function is usually used together with approximated diffraction propagators, which is fine for most imaging problems. However, these approximated diffraction propagators are not valid for Non-Line-of-Sight imaging scenarios. We show that the exact phasor field propagator (Rayleigh-Sommerfeld Diffraction) does not have a standard geometrical transformation, as compared to approximated diffraction propagators (Fresnel, Fraunhofer diffraction) that can be represented as shearing or rotation in the Wigner Distribution Function domain. Then, we explore differences between the exact and approximated solutions by characterizing errors made in different spatial positions and acquisition methods (confocal, non-confocal scanning). We derive a lateral resolution based on the exact phasor field propagator, which can be used as a reference for theoretical evaluations and comparisons. For targets that lie laterally outside a relay wall, the loss of resolution is geometrically illustrated in the context of the Wigner Distribution Function.},
  doi             = {10.1109/ICCP48838.2020.9105266},
  file            = {:D$\backslash$:/Download/09105266.pdf:pdf},
  isbn            = {9781728152301},
  keywords        = {Computational Imaging,Non-Line-of-Sight Imaging,Wigner Distribution Function},
  mendeley-groups = {NLOS/PhaseField},
}

@Article{Elten2019,
  author    = {Reza, Syed Azer and La Manna, Marco and Bauer, Sebastian and Velten, Andreas},
  journal   = {Opt. Express},
  title     = {Phasor field waves: experimental demonstrations of wave-like properties},
  year      = {2019},
  number    = {22},
  pages     = {32587--32608},
  volume    = {27},
  publisher = {Optical Society of America},
}

@Article{Liu,
  author          = {Liu, Xiaochun and Bauer, Sebastian and Velten, Andreas},
  journal         = {Nat. Commun.},
  title           = {{Phasor field diffraction based reconstruction for fast non-line-of-sight imaging systems}},
  issn            = {2041-1723},
  year            = {2020},
  doi             = {10.1038/s41467-020-15157-4},
  file            = {:C$\backslash$:/Users/Liao Zhengpeng/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Phasor field diffraction based reconstruction for fast non-line-of-sight imaging systems.pdf:pdf},
  mendeley-groups = {NLOS,NLOS/PhaseField},
  publisher       = {Springer US},
  url             = {http://dx.doi.org/10.1038/s41467-020-15157-4},
}

@Article{Bai2018,
  author          = {Bai, Lin and Zhao, Yiming and Huang, Xinming},
  journal         = {IEEE Trans. Circuit Syst II, Exp. Briefs},
  title           = {{A CNN Accelerator on FPGA Using Depthwise Separable Convolution}},
  year            = {2018},
  issn            = {15497747},
  number          = {10},
  pages           = {1415--1419},
  volume          = {65},
  abstract        = {Convolutional neural networks (CNNs) have been widely deployed in the fields of computer vision and pattern recognition because of their high accuracy. However, large convolution operations are computing-intensive that often requires a powerful computing platform such as Graphics Processing Unit (GPU). This makes it difficult to apply CNNs to portable devices. The state-of-the-art CNNs, such as MobileNetV2 and Xception, adopt depthwise separable convolution to replace the standard convolution for embedded platforms. That significantly reduces operations and parameters with only limited loss in accuracy. This highly structured model is very suitable for Field-Programmable Gate Array (FPGA) implementation. In this paper, a scalable high performance depthwise separable convolution optimized CNN accelerator is proposed. The accelerator can be fit into an FPGA of different sizes, provided the balancing between hardware resources and processing speed. As an example, MobileNetV2 is implemented on Arria 10 SoC FPGA, and the results show this accelerator can classify each picture from ImageNet in 3.75ms, which is about 266.6 frames per second. This achieves 20x speedup if compared to CPU.},
  archiveprefix   = {arXiv},
  arxivid         = {1809.01536},
  doi             = {10.1109/TCSII.2018.2865896},
  eprint          = {1809.01536},
  file            = {:C$\backslash$:/Users/Liao Zhengpeng/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/A CNN Accelerator on FPGA Using Depthwise Separable Convolution - 2018.pdf:pdf},
  keywords        = {Convolutional neural network,FPGA,MobileNetV2,hardware accelerator},
  mendeley-groups = {CNN/dw-model},
  publisher       = {IEEE},
}


@article{Deyang,
author = {Jiang, Deyang and Liu, Xiaochun and Luo, Jianwen and Liao, Zhengpeng and Velten, Andreas and Lou, Xin},
title = {Ring and Radius Sampling Based Phasor Field Diffraction Algorithm for Non-Line-of-Sight Reconstruction}
}

@article{baddour2011two,
  title={Two-dimensional Fourier transforms in polar coordinates},
  author={Baddour, Natalie},
  journal={Adv. Imaging Electron Phys.},
  volume={165},
  pages={1--45},
  year={2011},
  publisher={Elsevier}
}

@book{read2000restoration,
  title={Restoration of motion picture film},
  author={Read, Paul and Meyer, Mark-Paul},
  year={2000},
  publisher={Elsevier}
}

@Comment{jabref-meta: databaseType:bibtex;}
@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal={IEEE transactions on image processing},
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
  publisher={IEEE}
}

@article{DBLP:journals/corr/abs-2010-12737,
  author    = {Ji Hyun Nam and
               Eric Brandt and
               Sebastian Bauer and
               Xiaochun Liu and
               Eftychios Sifakis and
               Andreas Velten},
  title     = {Real-time Non-line-of-Sight imaging of dynamic scenes},
  journal   = {CoRR},
  volume    = {abs/2010.12737},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.12737},
  archivePrefix = {arXiv},
  eprint    = {2010.12737},
  timestamp = {Mon, 02 Nov 2020 18:17:09 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-12737.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{10.1007/978-3-030-58571-6_12,
author="Isogawa, Mariko
and Chan, Dorian
and Yuan, Ye
and Kitani, Kris
and O'Toole, Matthew",
editor="Vedaldi, Andrea
and Bischof, Horst
and Brox, Thomas
and Frahm, Jan-Michael",
title="Efficient Non-Line-of-Sight Imaging from Transient Sinograms",
booktitle="Computer Vision -- ECCV 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="193--208",
abstract="Non-line-of-sight (NLOS) imaging techniques use light that diffusely reflects off of visible surfaces (e.g., walls) to see around corners. One approach involves using pulsed lasers and ultrafast sensors to measure the travel time of multiply scattered light. Unlike existing NLOS techniques that generally require densely raster scanning points across the entirety of a relay wall, we explore a more efficient form of NLOS scanning that reduces both acquisition times and computational requirements. We propose a circular and confocal non-line-of-sight ({\$}{\$}{\backslash}text {\{}C{\}}^2{\backslash}text {\{}NLOS{\}}{\$}{\$}C2NLOS) scan that involves illuminating and imaging a common point, and scanning this point in a circular path along a wall. We observe that (1) these {\$}{\$}{\backslash}text {\{}C{\}}^2{\backslash}text {\{}NLOS{\}}{\$}{\$}C2NLOSmeasurements consist of a superposition of sinusoids, which we refer to as a transient sinogram, (2) there exists computationally efficient reconstruction procedures that transform these sinusoidal measurements into 3D positions of hidden scatterers or NLOS images of hidden objects, and (3) despite operating on an order of magnitude fewer measurements than previous approaches, these {\$}{\$}{\backslash}text {\{}C{\}}^2{\backslash}text {\{}NLOS{\}}{\$}{\$}C2NLOSscans provide sufficient information about the hidden scene to solve these different NLOS imaging tasks. We show results from both simulated and real {\$}{\$}{\backslash}text {\{}C{\}}^2{\backslash}text {\{}NLOS{\}}{\$}{\$}C2NLOSscans (Project page: https://marikoisogawa.github.io/project/c2nlos).",
isbn="978-3-030-58571-6"
}
@article{bertolotti2012non,
  title={Non-invasive imaging through opaque scattering layers},
  author={Bertolotti, Jacopo and Van Putten, Elbert G and Blum, Christian and Lagendijk, Ad and Vos, Willem L and Mosk, Allard P},
  journal={Nat.},
  volume={491},
  number={7423},
  pages={232--234},
  year={2012},
  publisher={Nature Publishing Group}
}
@article{katz2014non,
  title={Non-invasive single-shot imaging through scattering layers and around corners via speckle correlations},
  author={Katz, Ori and Heidmann, Pierre and Fink, Mathias and Gigan, Sylvain},
  journal={Nat. Photonics},
  volume={8},
  number={10},
  pages={784--790},
  year={2014},
  publisher={Nature Publishing Group}
}
@inproceedings{lindell2019acoustic,
  title={Acoustic non-line-of-sight imaging},
  author={Lindell, David B and Wetzstein, Gordon and Koltun, Vladlen},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
  pages={6780--6789},
  year={2019}
}
@inproceedings{bouman2017turning,
  title={Turning corners into cameras: Principles and methods},
  author={Bouman, Katherine L and Ye, Vickie and Yedidia, Adam B and Durand, Fr{\'e}do and Wornell, Gregory W and Torralba, Antonio and Freeman, William T},
  booktitle={IEEE Int. Conf. Comput. Vis},
  pages={2270--2278},
  year={2017}
}
@article{saunders2019computational,
  title={Computational periscopy with an ordinary digital camera},
  author={Saunders, Charles and Murray-Bruce, John and Goyal, Vivek K},
  journal={Nat.},
  volume={565},
  number={7740},
  pages={472--475},
  year={2019},
  publisher={Nature Publishing Group}
}
@article{boger2019passive,
  title={Passive optical time-of-flight for non line-of-sight localization},
  author={Boger-Lombard, Jeremy and Katz, Ori},
  journal={Nat. Commun.},
  volume={10},
  number={1},
  pages={1--9},
  year={2019},
  publisher={Nature Publishing Group}
}
@inproceedings{maeda2019thermal,
  title={Thermal non-line-of-sight imaging},
  author={Maeda, Tomohiro and Wang, Yiqin and Raskar, Ramesh and Kadambi, Achuta},
  booktitle={Proc. IEEE Int. Conf. Comput. Photography (ICCP)},
  pages={1--11},
  year={2019},
  organization={IEEE}
}
@article{kaga2019thermal,
  title={Thermal non-line-of-sight imaging from specular and diffuse reflections},
  author={Kaga, Masaki and Kushida, Takahiro and Takatani, Tsuyoshi and Tanaka, Kenichiro and Funatomi, Takuya and Mukaigawa, Yasuhiro},
  journal={IPSJ Trans. Comput. Vis. Appl.},
  volume={11},
  number={1},
  pages={1--6},
  year={2019},
  publisher={SpringerOpen}
}
@article{faccio2018trillion,
  title={A trillion frames per second: the techniques and applications of light-in-flight photography},
  author={Faccio, Daniele and Velten, Andreas},
  journal={Rep. Prog. Phys.},
  volume={81},
  number={10},
  pages={105901},
  year={2018},
  publisher={IOP Publishing}
}
@book{hariharan2002basics,
  title={Basics of holography},
  author={Hariharan, Parameswaran},
  year={2002},
  publisher={Cambridge university press}
}
@article{kadambi2013coded,
  title={Coded time of flight cameras: sparse deconvolution to address multipath interference and recover time profiles},
  author={Kadambi, Achuta and Whyte, Refael and Bhandari, Ayush and Streeter, Lee and Barsi, Christopher and Dorrington, Adrian and Raskar, Ramesh},
  journal={ACM Trans. Graph.},
  volume={32},
  number={6},
  pages={1--10},
  year={2013},
  publisher={ACM New York, NY, USA}
}
@article{peters2015solving,
  title={Solving trigonometric moment problems for fast transient imaging},
  author={Peters, Christoph and Klein, Jonathan and Hullin, Matthias B and Klein, Reinhard},
  journal={ACM Trans. Graph.},
  volume={34},
  number={6},
  pages={1--11},
  year={2015},
  publisher={ACM New York, NY, USA}
}
@article{jarabo2017recent,
  title={Recent advances in transient imaging: A computer graphics and vision perspective},
  author={Jarabo, Adrian and Masia, Belen and Marco, Julio and Gutierrez, Diego},
  journal={Visual Informatics},
  volume={1},
  number={1},
  pages={65--79},
  year={2017},
  publisher={Elsevier}
}
@article{gao2014single,
  title={Single-shot compressed ultrafast photography at one hundred billion frames per second},
  author={Gao, Liang and Liang, Jinyang and Li, Chiye and Wang, Lihong V},
  journal={Nat.},
  volume={516},
  number={7529},
  pages={74--77},
  year={2014},
  publisher={Nature Publishing Group}
}
@article{mikami2016ultrafast,
  title={Ultrafast optical imaging technology: principles and applications of emerging methods},
  author={Mikami, Hideharu and Gao, Liang and Goda, Keisuke},
  journal={Nanophotonics},
  volume={5},
  number={4},
  pages={497--509},
  year={2016},
  publisher={De Gruyter}
}
@article{zhu2016space,
  title={Space-and intensity-constrained reconstruction for compressed ultrafast photography},
  author={Zhu, Liren and Chen, Yujia and Liang, Jinyang and Xu, Qiaofeng and Gao, Liang and Ma, Cheng and Wang, Lihong V},
  journal={Optica},
  volume={3},
  number={7},
  pages={694--697},
  year={2016},
  publisher={Optical Society of America}
}
@inproceedings{jarabo2015relativistic,
  title={Relativistic Effects for Time-Resolved Light Transport},
  author={Jarabo, Adrian and Masia, Belen and Velten, Andreas and Barsi, Christopher and Raskar, Ramesh and Gutierrez, Diego},
  booktitle={Computer Graphics Forum},
  volume={34},
  number={8},
  pages={1--12},
  year={2015},
  organization={Wiley Online Library}
}
@book{becker2005advanced,
  title={Advanced time-correlated single photon counting techniques},
  author={Becker, Wolfgang},
  volume={81},
  year={2005},
  publisher={Springer Science \& Business Media}
}
@inproceedings{richardson200932,
  title={A 32$\times$ 32 50ps resolution 10 bit time to digital converter array in 130nm CMOS for time correlated imaging},
  author={Richardson, Justin and Walker, Richard and Grant, Lindsay and Stoppa, David and Borghetti, Fausto and Charbon, Edoardo and Gersbach, Marek and Henderson, Robert K},
  booktitle={2009 IEEE Custom Integrated Circuits Conference},
  pages={77--80},
  year={2009},
  organization={IEEE}
}
@article{richardson2011scaleable,
  title={Scaleable single-photon avalanche diode structures in nanometer CMOS technology},
  author={Richardson, Justin A and Webster, Eric AG and Grant, Lindsay A and Henderson, Robert K},
  journal={	IEEE Trans. Electron Devices},
  volume={58},
  number={7},
  pages={2028--2035},
  year={2011},
  publisher={IEEE}
}
@article{gersbach2012time,
  title={A time-resolved, low-noise single-photon image sensor fabricated in deep-submicron CMOS technology},
  author={Gersbach, Marek and Maruyama, Yuki and Trimananda, Rahmadi and Fishburn, Matt W and Stoppa, David and Richardson, Justin A and Walker, Richard and Henderson, Robert and Charbon, Edoardo},
  journal={IEEE J Solid-State Circuits},
  volume={47},
  number={6},
  pages={1394--1407},
  year={2012},
  publisher={IEEE}
}
@article{bronzi2014100,
  title={100 000 frames/s 64$\times$ 32 single-photon detector array for 2-D imaging and 3-D ranging},
  author={Bronzi, Danilo and Villa, Federica and Tisa, Simone and Tosi, Alberto and Zappa, Franco and Durini, Daniel and Weyers, Sascha and Brockherde, Werner},
  journal={IEEE J Sel Top Quantum Electron},
  volume={20},
  number={6},
  pages={354--363},
  year={2014},
  publisher={IEEE}
}
@inproceedings{burri2016linospad,
  title={LinoSPAD: a time-resolved 256x1 CMOS SPAD line sensor system featuring 64 FPGA-based TDC channels running at up to 8.5 giga-events per second},
  author={Burri, Samuel and Homulle, Harald and Bruschini, Claudio and Charbon, Edoardo},
  booktitle={Optical Sensing and Detection IV},
  volume={9899},
  pages={98990D},
  year={2016},
  organization={International Society for Optics and Photonics}
}
@inproceedings{itzler2008geiger,
  title={Geiger-mode APD single photon detectors},
  author={Itzler, Mark A and Jiang, Xudong and Ben-Michael, Rafael and Nyman, Bruce and Slomkowski, Krystyna},
  booktitle={Optical Fiber Communication Conference},
  pages={OMK4},
  year={2008},
  organization={Optical Society of America}
}
@inproceedings{itzler2008single,
  title={Single photon avalanche photodiodes for near-infrared photon counting},
  author={Itzler, Mark A and Jiang, Xudong and Ben-Michael, Rafael and Nyman, Bruce and Slomkowski, Krystyna},
  booktitle={Quantum Sensing and Nanophotonic Devices V},
  volume={6900},
  pages={69001E},
  year={2008},
  organization={International Society for Optics and Photonics}
}
@article{itzler2007single,
  title={Single photon avalanche diodes (SPADs) for 1.5 $\mu$ m photon counting applications},
  author={Itzler, Mark A and Ben-Michael, R and Hsu, C-F and Slomkowski, Krystyna and Tosi, Alberto and Cova, Sergio and Zappa, Franco and Ispasoiu, Radu},
  journal={J. Mod. Opt.},
  volume={54},
  number={2-3},
  pages={283--304},
  year={2007},
  publisher={Taylor \& Francis}
}
@article{musarra2019non,
  title={Non-line-of-sight three-dimensional imaging with a single-pixel camera},
  author={Musarra, Gabriella and Lyons, Ashley and Conca, Enrico and Altmann, Yoann and Villa, Federica and Zappa, F and Padgett, Miles J and Faccio, Daniele},
  journal={Phys. Rev. Appl.},
  volume={12},
  number={1},
  pages={011002},
  year={2019},
  publisher={APS}
}
@article{gariepy2015single,
  title={Single-photon sensitive light-in-fight imaging},
  author={Gariepy, Genevieve and Krstaji{\'c}, Nikola and Henderson, Robert and Li, Chunyong and Thomson, Robert R and Buller, Gerald S and Heshmat, Barmak and Raskar, Ramesh and Leach, Jonathan and Faccio, Daniele},
  journal={Nat. Commun.},
  volume={6},
  number={1},
  pages={1--7},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{chan2017non,
  title={Non-line-of-sight tracking of people at long range},
  author={Chan, Susan and Warburton, Ryan E and Gariepy, Genevieve and Leach, Jonathan and Faccio, Daniele},
  journal={Opt. Express},
  volume={25},
  number={9},
  pages={10109--10117},
  year={2017},
  publisher={Optical Society of America}
}
@inproceedings{lindell2018towards,
  title={Towards transient imaging at interactive rates with single-photon detectors},
  author={Lindell, David B and O'Toole, Matthew and Wetzstein, Gordon},
  booktitle={Proc. IEEE Int. Conf. Comput. Photography (ICCP)},
  pages={1--8},
  year={2018},
  organization={IEEE}
}
@article{gariepy2016detection,
  title={Detection and tracking of moving objects hidden from view},
  author={Gariepy, Genevieve and Tonolini, Francesco and Henderson, Robert and Leach, Jonathan and Faccio, Daniele},
  journal={Nat. Photonics},
  volume={10},
  number={1},
  pages={23--26},
  year={2016},
  publisher={Nature Publishing Group}
}
@article{buttafava2015non,
  title={Non-line-of-sight imaging using a time-gated single photon avalanche diode},
  author={Buttafava, Mauro and Zeman, Jessica and Tosi, Alberto and Eliceiri, Kevin and Velten, Andreas},
  journal={Opt. Express},
  volume={23},
  number={16},
  pages={20997--21011},
  year={2015},
  publisher={Optical Society of America}
}
@inproceedings{o2017reconstructing,
  title={Reconstructing transient images from single-photon sensors},
  author={O'Toole, Matthew and Heide, Felix and Lindell, David B and Zang, Kai and Diamond, Steven and Wetzstein, Gordon},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
  pages={1539--1547},
  year={2017}
}
@article{starshynov2019coherent,
  title={Coherent control of light for non-line-of-sight imaging},
  author={Starshynov, Ilya and Ghafur, Omair and Fitches, James and Faccio, Daniele},
  journal={Phys. Rev. Appl.},
  volume={12},
  number={6},
  pages={064045},
  year={2019},
  publisher={APS}
}
@inproceedings{pediredla2019snlos,
  title={Snlos: Non-line-of-sight scanning through temporal focusing},
  author={Pediredla, Adithya and Dave, Akshat and Veeraraghavan, Ashok},
  booktitle={Proc. IEEE Int. Conf. Comput. Photography (ICCP)},
  pages={1--13},
  year={2019},
  organization={IEEE}
}
@article{gupta2012reconstruction,
  title={Reconstruction of hidden 3D shapes using diffuse reflections},
  author={Gupta, Otkrist and Willwacher, Thomas and Velten, Andreas and Veeraraghavan, Ashok and Raskar, Ramesh},
  journal={Opt. Express},
  volume={20},
  number={17},
  pages={19096--19108},
  year={2012},
  publisher={Optical Society of America}
}
@inproceedings{wu2012frequency,
  title={Frequency analysis of transient light transport with applications in bare sensor imaging},
  author={Wu, Di and Wetzstein, Gordon and Barsi, Christopher and Willwacher, Thomas and O’Toole, Matthew and Naik, Nikhil and Dai, Qionghai and Kutulakos, Kyros and Raskar, Ramesh},
  booktitle={Proc. Eur. Conf. Comput. Vis.},
  pages={542--555},
  year={2012},
  organization={Springer}
}
@inproceedings{heide2014diffuse,
  title={Diffuse mirrors: 3D reconstruction from diffuse indirect illumination using inexpensive time-of-flight sensors},
  author={Heide, Felix and Xiao, Lei and Heidrich, Wolfgang and Hullin, Matthias B},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
  pages={3222--3229},
  year={2014}
}
@inproceedings{tancik2018data,
  title={Data-driven non-line-of-sight imaging with a traditional camera},
  author={Tancik, Matthew and Swedish, Tristan and Satat, Guy and Raskar, Ramesh},
  booktitle={Imaging Systems and Applications},
  pages={IW2B--6},
  year={2018},
  organization={Optical Society of America}
}
@inproceedings{chen2019steady,
  title={Steady-state non-line-of-sight imaging},
  author={Chen, Wenzheng and Daneau, Simon and Mannan, Fahim and Heide, Felix},
  booktitle={Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR)},
  pages={6790--6799},
  year={2019}
}

@article{stolt1978migration,
  title={Migration by Fourier transform},
  author={Stolt, Robert H},
  journal={Geophysics},
  volume={43},
  number={1},
  pages={23--48},
  year={1978},
  publisher={Society of Exploration Geophysicists}
}

@article{callow2003signal,
  title={Signal processing for synthetic aperture sonar image enhancement},
  author={Callow, Hayden J},
  year={2003},
  publisher={University of Canterbury. Electrical and Electronic Engineering}
}

@inproceedings{sheriff1992synthetic,
  title={Synthetic aperture beamforming with automatic phase compensation for high frequency sonars},
  author={Sheriff, Robert W},
  booktitle={Proceedings of the 1992 symposium on autonomous underwater vehicle technology},
  pages={236--245},
  year={1992},
  organization={IEEE}
}
@article{tasinkevych2014circular,
  title={Circular radon transform inversion technique in synthetic aperture ultrasound imaging: an ultrasound phantom evaluation},
  author={Tasinkevych, Jurij and Trots, Ihor},
  journal={	Arch. Acoust.},
  volume={39},
  number={4},
  pages={569--582},
  year={2014}
}
@article{moon2014determination,
  title={On the determination of a function from an elliptical Radon transform},
  author={Moon, Sunghwan},
  journal={J. Math. Anal. Appl.},
  volume={416},
  number={2},
  pages={724--734},
  year={2014},
  publisher={Elsevier}
}
@article{buttafava2014time,
  title={Time-gated single-photon detection module with 110 ps transition time and up to 80 MHz repetition rate},
  author={Buttafava, Mauro and Boso, Gianluca and Ruggeri, Alessandro and Dalla Mora, Alberto and Tosi, Alberto},
  journal={Rev. Sci. Instrum.},
  volume={85},
  number={8},
  pages={083114},
  year={2014},
  publisher={American Institute of Physics}
}
@article{zappa2007principles,
  title={Principles and features of single-photon avalanche diode arrays},
  author={Zappa, Franco and Tisa, Simone and Tosi, Alberto and Cova, Sergio},
  journal={Sensors and Actuators A: Physical},
  volume={140},
  number={1},
  pages={103--112},
  year={2007},
  publisher={Elsevier}
}

@book{hennessy2011computer,
  title={Computer architecture: a quantitative approach},
  author={Hennessy, John L and Patterson, David A},
  year={2011},
  publisher={Elsevier}
}

@article{nam2021low,
  title={Low-latency time-of-flight non-line-of-sight imaging at 5 frames per second},
  author={Nam, Ji Hyun and Brandt, Eric and Bauer, Sebastian and Liu, Xiaochun and Renna, Marco and Tosi, Alberto and Sifakis, Eftychios and Velten, Andreas},
  doi = {10.1038/s41467-021-26721-x},
  url = {http://doi.org/10.1038/s41467-021-26721-x},
  journal={Nat. Commun.},
  volume={12},
  number={1},
  pages={1--10},
  year={2021},
  publisher={Nature Publishing Group}
}
@article{jiang2021ring,
  title={Ring and Radius Sampling Based Phasor Field Diffraction Algorithm for Non-Line-of-Sight Reconstruction},
  author={Jiang, Deyang and Liu, Xiaochun and Luo, Jianwen and Liao, Zhengpeng and Velten, Andreas and Lou, Xin},
  journal={IEEE Trans. Pattern Anal. Mach. Intell.},
  number={01},
  pages={1--1},
  year={2021},
  publisher={IEEE Computer Society}
}

@article{liao2021fpga,
  title={FPGA Accelerator for Real-Time Non-Line-of-Sight Imaging},
  author={Liao, Zhengpeng and Jiang, Deyang and Liu, Xiaochun and Velten, Andreas and Ha, Yajun and Lou, Xin},
  journal={IEEE Trans. Circuits Syst. I: Regul. Pap.},
  year={2021},
  publisher={IEEE}
}

@article{caramazza2018neural,
  title={Neural network identification of people hidden from view with a single-pixel, single-photon detector},
  author={Caramazza, Piergiorgio and Boccolini, Alessandro and Buschek, Daniel and Hullin, Matthias and Higham, Catherine F and Henderson, Robert and Murray-Smith, Roderick and Faccio, Daniele},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={1--6},
  year={2018},
  publisher={Nature Publishing Group}
}
